{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/azizbarank/distilroberta-base-sst-2-distilled/blob/main/knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xknRaAfngCT1"
   },
   "source": [
    "## Installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "285QJOlK9Z2W",
    "outputId": "c4169aea-40e4-4e75-8c29-d3faa58ff92b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (4.23.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (2.6.1)\n",
      "Requirement already satisfied: tensorboard in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (3.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (2022.10.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (10.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (1.5.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (1.50.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (2.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard) (4.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/envs/causal_nlp/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n",
      "[sudo] password for juhyeon: "
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets tensorboard\n",
    "!sudo apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFefM0LdgJkH"
   },
   "source": [
    "## Chhosing our \"teacher\" and \"student\" models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "wrQyPjcl9-Ol"
   },
   "outputs": [],
   "source": [
    "student = \"distilroberta-base\" # this is just placeholder ignore\n",
    "teacher = \"klue/roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxo4XGgRgQhO"
   },
   "source": [
    "## Loading our SST-2 part of the GLUE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "e9acdb1a1d2643819339b8f0cf3cecd1",
      "135dbaaa41a946ca899dc8164bca3e44",
      "09db8fe0b55443fdab2ac54e84bb7ff5",
      "b591e297adff46fa8df014fe9192caa3",
      "8c2682025ce14a88b39dbfc826e33954",
      "5ad3705618644447bfcfdb9b65271883",
      "b71e32972c104b53a669ec7591e557ff",
      "861ab3f25cb4479f9ace3978dc315ecf",
      "52eabebd19834610890b10347acaf05a",
      "e39bf65dc61a4836805a0a8bd23503a3",
      "a864568c3b89405cb3ca8e36180f9e61"
     ]
    },
    "id": "ZhFP95R3-xs-",
    "outputId": "f5248a08-07c1-4640-f397-a370c2a60e53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset klue (/home/seungjoonpark/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 157.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"klue\", \"sts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nM5nz3GOgXoG"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlAARAR8ge9r"
   },
   "source": [
    "### Initiating the tokenizer of our student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "9e2728489569432394255a3bb3a80247",
      "af6bdd67d22a42f0be80845511720ae0",
      "3b32dbed334941b881ae0e563d7c40ce",
      "6abc6629a8b0412c9b09ad02c3376127",
      "8722d84268664df5a8012a83afd575f3",
      "3ddd98a8524042adba2bbaab1dbf60af",
      "8a1e9c4517dc463ba78b91b16431008a",
      "0a8902cb735d4f658fd387204149ace6",
      "e25584843ddd4a4484ec94e7e6c0f6a0",
      "155517c19bc24d599b068af7e28ad8cf",
      "3838ac5a07244d7da893c8ba71b21fd9"
     ]
    },
    "id": "-pTJHVMv-7fz",
    "outputId": "d5047064-b098-435b-938c-ffd0c4a3ed9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "ea941579121247548fdf7774079f2f5b",
      "0faf64a0c2af4340ac3b0eed24732d5a",
      "cde2d6e48a7748ca840c745e52fa06c2",
      "7874b0b368c24ef7b15fac3a4ed83582",
      "a255def76d9b4c9db5d9cc7385fc9e6d",
      "b0614b4ade314c5c8073193bb1d3408f",
      "38b21b8459234a42b8fb69752644d48a",
      "5ffb8a1db11a43cb8602ec7af8c55f77",
      "5293a6fc609849eda02622c6fa5b2167",
      "c9403580e4524754980170c5f1130bd9",
      "1e5da5a29aaa4700bcdbdfc768b33aaf"
     ]
    },
    "id": "4W4oB3mzHJlb",
    "outputId": "60e0f718-85e2-4b4b-ae18-48e52f6453cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:00<00:00, 25.58ba/s]\n",
      "Loading cached processed dataset at /home/seungjoonpark/.cache/huggingface/datasets/klue/sts/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e/cache-546f76030e6fb252.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': Value(dtype='int64', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, max_length=512\n",
    "    )\n",
    "    t = lambda x: x[\"binary-label\"]\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = list(map(t, examples[\"labels\"]))\n",
    "    return tokenized_inputs\n",
    "\n",
    "sst2_enc = dataset.map(process, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "# sst2_enc = sst2_enc.rename_column(\"label\",\"labels\")\n",
    "# sst2_enc[\"train\"][\"labels\"] = sst2_enc[\"train\"][\"labels\"][\"binary-label\"]\n",
    "# sst2_enc[\"validation\"][\"labels\"] = sst2_enc[\"validation\"][\"labels\"][\"binary-label\"]\n",
    "# t = lambda x: x[\"binary-label\"]\n",
    "\n",
    "# sst2_enc[\"train\"][\"labels\"] = list(map(t, sst2_enc[\"train\"][\"labels\"]))\n",
    "# sst2_enc[\"validation\"][\"labels\"] = list(map(t, sst2_enc[\"validation\"][\"labels\"]))\n",
    "\n",
    "sst2_enc[\"validation\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGE72or9gsGn"
   },
   "source": [
    "## Creating our Knowledge Distillation Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "JayX6RkQ_GZf"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "class DistillationTrainingArguments(TrainingArguments):\n",
    "    def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "GdeAjnlUERab"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self._move_model_to_device(self.teacher,self.model.device)\n",
    "        self.teacher.eval()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "        # compute student output\n",
    "        outputs_student = model(**inputs)\n",
    "        student_loss=outputs_student.loss\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(**inputs)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs_student.logits.size() == outputs_teacher.logits.size()\n",
    "\n",
    "        # compute distillation loss and soften probabilities\n",
    "        loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#         cos_loss_function = nn.CosineEmbeddingLoss(reduction=\"mean\")\n",
    "        \n",
    "        loss_logits = (loss_function(\n",
    "            F.log_softmax(outputs_student.logits / self.args.temperature, dim=-1),\n",
    "            F.softmax(outputs_teacher.logits / self.args.temperature, dim=-1)) * (self.args.temperature ** 2))\n",
    "        # return weighted student loss\n",
    "        loss = self.args.alpha * student_loss + (1. - self.args.alpha) * loss_logits\n",
    "        return (loss, outputs_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of9nToqqhF9Y"
   },
   "source": [
    "## Defining the Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZl-LLhKJLIZ",
    "outputId": "e6d2270a-02d1-4074-f546-b536697d30fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-02f4a3120817>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWpFJ4gKiEri"
   },
   "source": [
    "## Teacher Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/seungjoonpark/.cache/huggingface/hub/models--klue--roberta-base/snapshots/67dd433d36ebc66a42c9aaa85abcf8d2620e41d9/pytorch_model.bin\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### to continue learning\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    teacher,\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    # checkpoint\n",
    "    output_dir='./models/',\n",
    "    # overwrite_output_dir=True,\n",
    "\n",
    "    # Model Save & Load\n",
    "    save_strategy = \"epoch\", # 'steps'\n",
    "    load_best_model_at_end=True,\n",
    "    # save_steps = 500,\n",
    "\n",
    "\n",
    "    # Dataset\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    \n",
    "    # Optimizer\n",
    "    learning_rate=2e-5, # 5e-5\n",
    "    weight_decay=0.01,  # 0\n",
    "    # warmup_steps=200,b\n",
    "\n",
    "    # Resularization\n",
    "    # max_grad_norm = 1.0,\n",
    "    # label_smoothing_factor=0.1,\n",
    "\n",
    "\n",
    "    # Evaluation \n",
    "    metric_for_best_model='eval_f1',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "\n",
    "    # Randomness\n",
    "    seed=33,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    teacher_model,\n",
    "    args,\n",
    "    train_dataset=sst2_enc[\"train\"],\n",
    "    eval_dataset=sst2_enc['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjoonpark/miniconda3/envs/nlp_project/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11668\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 02:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367865</td>\n",
       "      <td>0.845857</td>\n",
       "      <td>0.843245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.580463</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.832367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.474899</td>\n",
       "      <td>0.840077</td>\n",
       "      <td>0.837448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702090</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>0.847401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.727276</td>\n",
       "      <td>0.845857</td>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./models/checkpoint-92\n",
      "Configuration saved in ./models/checkpoint-92/config.json\n",
      "Model weights saved in ./models/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-92/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./models/checkpoint-184\n",
      "Configuration saved in ./models/checkpoint-184/config.json\n",
      "Model weights saved in ./models/checkpoint-184/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-184/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-184/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./models/checkpoint-276\n",
      "Configuration saved in ./models/checkpoint-276/config.json\n",
      "Model weights saved in ./models/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-276/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./models/checkpoint-368\n",
      "Configuration saved in ./models/checkpoint-368/config.json\n",
      "Model weights saved in ./models/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-368/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to ./models/checkpoint-460\n",
      "Configuration saved in ./models/checkpoint-460/config.json\n",
      "Model weights saved in ./models/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in ./models/checkpoint-460/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./models/checkpoint-368 (score: 0.8474012319258611).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=460, training_loss=0.08918315224025561, metrics={'train_runtime': 166.2645, 'train_samples_per_second': 350.887, 'train_steps_per_second': 2.767, 'total_flos': 2967119815735680.0, 'train_loss': 0.08918315224025561, 'epoch': 5.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models/checkpoint-368/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./models/checkpoint-368/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./models/checkpoint-368.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "teacher_model = teacher_model.from_pretrained('./models/checkpoint-368')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig\n",
    "from transformers import AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "loading configuration file config.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--distilroberta-base/snapshots/d5411c3ee9e1793fd9ef58390b40a80a4c10df32/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/seungjoonpark/.cache/huggingface/hub/models--distilroberta-base/snapshots/d5411c3ee9e1793fd9ef58390b40a80a4c10df32/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32000, 768)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "# id2label, label2id dicts for the outputs for the model\n",
    "num_labels = 2\n",
    "\n",
    "# my_config = DistilBertConfig(activation=\"gelu\", attention_dropout=0.4, vocab_size=32000, n_layers=6, num_labels=6,\n",
    "#                              hidden_dim=768, label2id=label2id, id2label=id2label)\n",
    "# my_config.save_pretrained(save_directory='./models/distilkoroberta')    \n",
    "\n",
    "# training arguments\n",
    "training_args = DistillationTrainingArguments(\n",
    "    output_dir=\"distilroberta-base-sst2-distilled\",\n",
    "    num_train_epochs=7, per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128, fp16=True, \n",
    "    learning_rate=6e-5, seed=33, \n",
    "    logging_dir=f\"distilroberta-base-sst2-distilled/logs\",\n",
    "    logging_strategy=\"epoch\", evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", save_total_limit=2, \n",
    "    load_best_model_at_end=True, metric_for_best_model=\"accuracy\", \n",
    "    report_to=\"tensorboard\", push_to_hub=False,\n",
    "    alpha=0.5, temperature=4.0\n",
    "    )\n",
    "\n",
    "# data_collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# # teacher model\n",
    "# teacher_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     teacher,\n",
    "#     num_labels=num_labels)\n",
    "\n",
    "# student model\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student,\n",
    "    num_labels=num_labels)\n",
    "student_model.resize_token_embeddings(32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "### to continue learning\n",
    "\n",
    "training_args = DistillationTrainingArguments(\n",
    "    output_dir=\"distilroberta-base-sst2-distilled\",\n",
    "    num_train_epochs=7, per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128, fp16=True, \n",
    "    learning_rate=6e-5, seed=33, \n",
    "    logging_dir=f\"distilroberta-base-sst2-distilled/logs\",\n",
    "    logging_strategy=\"epoch\", evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", save_total_limit=2, \n",
    "    load_best_model_at_end=True, metric_for_best_model=\"accuracy\", \n",
    "    report_to=\"tensorboard\", push_to_hub=False,\n",
    "    alpha=0.5, temperature=4.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    student_model,\n",
    "    training_args,\n",
    "    teacher_model=teacher_model,\n",
    "    train_dataset=sst2_enc[\"train\"],\n",
    "    eval_dataset=sst2_enc[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjoonpark/miniconda3/envs/nlp_project/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11668\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [644/644 02:18, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>1.611867</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.562734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>1.225722</td>\n",
       "      <td>0.620424</td>\n",
       "      <td>0.618156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>1.149848</td>\n",
       "      <td>0.649326</td>\n",
       "      <td>0.648636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>1.089765</td>\n",
       "      <td>0.647399</td>\n",
       "      <td>0.647315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>1.235284</td>\n",
       "      <td>0.630058</td>\n",
       "      <td>0.629749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>1.098776</td>\n",
       "      <td>0.668593</td>\n",
       "      <td>0.667407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>1.094123</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>0.663539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-92\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-92/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-92/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-460] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-184\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-184/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-184/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-184/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-184/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-644] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-276\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-276/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-276/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-92] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-368\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-368/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-368/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-184] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-460\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-460/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-460/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-368] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-552\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-552/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-552/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-552/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-552/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-276] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-644\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-644/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-644/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-644/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-644/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-460] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilroberta-base-sst2-distilled/checkpoint-552 (score: 0.6685934489402697).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=644, training_loss=0.2154033028561136, metrics={'train_runtime': 138.9617, 'train_samples_per_second': 587.759, 'train_steps_per_second': 4.634, 'total_flos': 2094145023404592.0, 'train_loss': 0.2154033028561136, 'epoch': 7.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "teacher_trainer = Trainer(teacher_model,\n",
    "                          training_args,\n",
    "                          train_dataset=sst2_enc[\"train\"],\n",
    "                          eval_dataset=sst2_enc[\"validation\"],\n",
    "                          data_collator=data_collator,\n",
    "                          tokenizer=tokenizer,\n",
    "                          compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_weights = []\n",
    "for i, p in enumerate(student_model.parameters()):\n",
    "    student_weights.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized one layer out of two\n",
    "teacher_weights = []\n",
    "for i, p in enumerate(teacher_model.parameters()):\n",
    "    teacher_weights.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0304,  0.0341, -0.0020,  ...,  0.0046,  0.0323, -0.0413],\n",
       "        [-0.0053,  0.0412, -0.0305,  ...,  0.0160, -0.0263,  0.0135]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First and last layers\n",
    "student_weights[0].data.copy_(teacher_weights[0].data)\n",
    "student_weights[1].data.copy_(teacher_weights[1].data)\n",
    "student_weights[2].data.copy_(teacher_weights[2].data)\n",
    "student_weights[-1].data.copy_(teacher_weights[-1].data)\n",
    "student_weights[-2].data.copy_(teacher_weights[-2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 3\n",
    "for i in range(12):\n",
    "    if i % 2 == 1:\n",
    "        std_idx = i // 2\n",
    "        for j in range(16):\n",
    "            student_weights[base+std_idx*16+j].data.copy_(teacher_weights[base+i*16+j].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters())[:-2]:\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "### to continue learning\n",
    "\n",
    "training_args = DistillationTrainingArguments(\n",
    "    output_dir=\"distilroberta-base-sst2-distilled\",\n",
    "    num_train_epochs=7, per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128, fp16=True, \n",
    "    learning_rate=6e-5, seed=33, \n",
    "    logging_dir=f\"distilroberta-base-sst2-distilled/logs\",\n",
    "    logging_strategy=\"epoch\", evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", save_total_limit=2, \n",
    "    load_best_model_at_end=True, metric_for_best_model=\"accuracy\", \n",
    "    report_to=\"tensorboard\", push_to_hub=False,\n",
    "    alpha=0.5, temperature=4.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    student_model,\n",
    "    training_args,\n",
    "    teacher_model=teacher_model,\n",
    "    train_dataset=sst2_enc[\"train\"],\n",
    "    eval_dataset=sst2_enc[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjoonpark/miniconda3/envs/nlp_project/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11668\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [644/644 02:18, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.827755</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.734780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>1.300967</td>\n",
       "      <td>0.695568</td>\n",
       "      <td>0.690409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.807425</td>\n",
       "      <td>0.732177</td>\n",
       "      <td>0.730734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.607502</td>\n",
       "      <td>0.805395</td>\n",
       "      <td>0.805383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.524736</td>\n",
       "      <td>0.789981</td>\n",
       "      <td>0.789728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.630178</td>\n",
       "      <td>0.786127</td>\n",
       "      <td>0.786114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.632832</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>0.774513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-92\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-92/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-92/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-552] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-184\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-184/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-184/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-184/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-184/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-644] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-276\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-276/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-276/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-184] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-368\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-368/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-368/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-92] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-460\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-460/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-460/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-276] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-552\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-552/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-552/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-552/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-552/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-460] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-644\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-644/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-644/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-644/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-644/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-552] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilroberta-base-sst2-distilled/checkpoint-368 (score: 0.8053949903660886).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=644, training_loss=0.24401173828551487, metrics={'train_runtime': 138.8455, 'train_samples_per_second': 588.251, 'train_steps_per_second': 4.638, 'total_flos': 2094145023404592.0, 'train_loss': 0.24401173828551487, 'epoch': 7.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), './models/distilkoroberta_first_7epochs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradual Decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher_model\n",
    "        self._move_model_to_device(self.teacher,self.model.device)\n",
    "        self.teacher.eval()\n",
    "        self.step = 0\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        self.step += 1\n",
    "        if self.step < 644 * 0.8:\n",
    "            alpha = 1.\n",
    "        elif self.step < 644 * 0.9:\n",
    "            alpha = 0.5\n",
    "        else:\n",
    "            alpha = 0.\n",
    "        \n",
    "        # compute student output\n",
    "        outputs_student = model(**inputs)\n",
    "        student_loss=outputs_student.loss\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(**inputs)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs_student.logits.size() == outputs_teacher.logits.size()\n",
    "\n",
    "        # compute distillation loss and soften probabilities\n",
    "        loss_function = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#         cos_loss_function = nn.CosineEmbeddingLoss(reduction=\"mean\")\n",
    "        \n",
    "        loss_logits = (loss_function(\n",
    "            F.log_softmax(outputs_student.logits / self.args.temperature, dim=-1),\n",
    "            F.softmax(outputs_teacher.logits / self.args.temperature, dim=-1)) * (self.args.temperature ** 2))\n",
    "        # return weighted student loss\n",
    "        loss = (1. - alpha) * student_loss + 1.* alpha * loss_logits\n",
    "        return (loss, outputs_student) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./models/checkpoint-368/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"klue/roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ./models/checkpoint-368/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./models/checkpoint-368.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/seungjoonpark/.cache/huggingface/hub/models--distilroberta-base/snapshots/d5411c3ee9e1793fd9ef58390b40a80a4c10df32/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/seungjoonpark/.cache/huggingface/hub/models--distilroberta-base/snapshots/d5411c3ee9e1793fd9ef58390b40a80a4c10df32/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32000, 768)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "teacher_model = teacher_model.from_pretrained('./models/checkpoint-368')\n",
    "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    student,\n",
    "    num_labels=num_labels)\n",
    "student_model.resize_token_embeddings(32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "### to continue learning\n",
    "\n",
    "training_args = DistillationTrainingArguments(\n",
    "    output_dir=\"distilroberta-base-sst2-distilled\",\n",
    "    num_train_epochs=7, per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128, fp16=True, \n",
    "    learning_rate=6e-5, seed=33, \n",
    "    logging_dir=f\"distilroberta-base-sst2-distilled/logs\",\n",
    "    logging_strategy=\"epoch\", evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", save_total_limit=2, \n",
    "    load_best_model_at_end=True, metric_for_best_model=\"accuracy\", \n",
    "    report_to=\"tensorboard\", push_to_hub=False,\n",
    "    alpha=0.5, temperature=4.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    student_model,\n",
    "    training_args,\n",
    "    teacher_model=teacher_model,\n",
    "    train_dataset=sst2_enc[\"train\"],\n",
    "    eval_dataset=sst2_enc[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seungjoonpark/miniconda3/envs/nlp_project/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 11668\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [644/644 02:19, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.995600</td>\n",
       "      <td>1.568988</td>\n",
       "      <td>0.766859</td>\n",
       "      <td>0.765013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.620300</td>\n",
       "      <td>1.617660</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.738763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>1.455085</td>\n",
       "      <td>0.743738</td>\n",
       "      <td>0.742760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>1.279669</td>\n",
       "      <td>0.786127</td>\n",
       "      <td>0.786099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>1.208770</td>\n",
       "      <td>0.788054</td>\n",
       "      <td>0.787921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>1.074637</td>\n",
       "      <td>0.793834</td>\n",
       "      <td>0.793316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.961360</td>\n",
       "      <td>0.782274</td>\n",
       "      <td>0.782274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-92\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-92/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-92/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-184\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-184/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-184/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-184/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-184/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-644] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-276\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-276/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-276/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-184] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-368\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-368/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-368/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-92] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-460\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-460/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-460/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-276] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-552\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-552/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-552/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-552/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-552/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-368] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to distilroberta-base-sst2-distilled/checkpoint-644\n",
      "Configuration saved in distilroberta-base-sst2-distilled/checkpoint-644/config.json\n",
      "Model weights saved in distilroberta-base-sst2-distilled/checkpoint-644/pytorch_model.bin\n",
      "tokenizer config file saved in distilroberta-base-sst2-distilled/checkpoint-644/tokenizer_config.json\n",
      "Special tokens file saved in distilroberta-base-sst2-distilled/checkpoint-644/special_tokens_map.json\n",
      "Deleting older checkpoint [distilroberta-base-sst2-distilled/checkpoint-460] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from distilroberta-base-sst2-distilled/checkpoint-552 (score: 0.7938342967244701).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=644, training_loss=0.5088177630619973, metrics={'train_runtime': 139.3844, 'train_samples_per_second': 585.977, 'train_steps_per_second': 4.62, 'total_flos': 2094145023404592.0, 'train_loss': 0.5088177630619973, 'epoch': 7.0})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning on Downstream Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = deepcopy(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset klue/nli (download: 1.20 MiB, generated: 6.10 MiB, post-processed: Unknown size, total: 7.30 MiB) to /home/seungjoonpark/.cache/huggingface/datasets/klue/nli/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.26M/1.26M [00:00<00:00, 6.19MB/s]\n",
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset klue downloaded and prepared to /home/seungjoonpark/.cache/huggingface/datasets/klue/nli/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 422.51it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"klue\", 'nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 5.76kB [00:00, 2.14MB/s]                   \n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: íž›ê±¸ ì§„ì‹¬ ìµœê³ ë‹¤ ê·¸ ì–´ë–¤ ížˆì–´ë¡œë³´ë‹¤ ë©‹ì§€ë‹¤\n",
      "Sentence 2: íž›ê±¸ ì§„ì‹¬ ìµœê³ ë¡œ ë©‹ì§€ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "sentence1_key, sentence2_key = (\"premise\", \"hypothesis\")\n",
    "print(f\"Sentence 1: {datasets['train'][0][sentence1_key]}\")\n",
    "print(f\"Sentence 2: {datasets['train'][0][sentence2_key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:01<00:00, 21.61ba/s]\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00, 15.01ba/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[sentence1_key],\n",
    "        examples[sentence2_key],\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "encoded_datasets = datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"relu\",\n",
       "  \"attention_dropout\": 0.4,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"transformers_version\": \"4.23.1\",\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['classifier.weight', 'classifier.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 3\n",
    "my_config = DistilBertConfig(activation=\"relu\", attention_dropout=0.4, vocab_size=32000, n_layers=6, num_labels=num_labels)\n",
    "model = AutoModelForSequenceClassification.from_config(my_config)\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = torch.load(\"/home/seungjoonpark/DistilKoBERT/models/distilkoroberta.pt\")\n",
    "del pretrained_dict[next(reversed(pretrained_dict))]\n",
    "del pretrained_dict[next(reversed(pretrained_dict))]\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "model_dict.update(pretrained_dict) \n",
    "model.load_state_dict(pretrained_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"test-nli\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/seungjoonpark/miniconda3/envs/nlp_project/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 24998\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 490\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.097590</td>\n",
       "      <td>0.380333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.113917</td>\n",
       "      <td>0.390667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.146158</td>\n",
       "      <td>0.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.126838</td>\n",
       "      <td>0.397333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.137593</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to test-nli/checkpoint-98\n",
      "Configuration saved in test-nli/checkpoint-98/config.json\n",
      "Model weights saved in test-nli/checkpoint-98/pytorch_model.bin\n",
      "tokenizer config file saved in test-nli/checkpoint-98/tokenizer_config.json\n",
      "Special tokens file saved in test-nli/checkpoint-98/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to test-nli/checkpoint-196\n",
      "Configuration saved in test-nli/checkpoint-196/config.json\n",
      "Model weights saved in test-nli/checkpoint-196/pytorch_model.bin\n",
      "tokenizer config file saved in test-nli/checkpoint-196/tokenizer_config.json\n",
      "Special tokens file saved in test-nli/checkpoint-196/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to test-nli/checkpoint-294\n",
      "Configuration saved in test-nli/checkpoint-294/config.json\n",
      "Model weights saved in test-nli/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in test-nli/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in test-nli/checkpoint-294/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to test-nli/checkpoint-392\n",
      "Configuration saved in test-nli/checkpoint-392/config.json\n",
      "Model weights saved in test-nli/checkpoint-392/pytorch_model.bin\n",
      "tokenizer config file saved in test-nli/checkpoint-392/tokenizer_config.json\n",
      "Special tokens file saved in test-nli/checkpoint-392/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to test-nli/checkpoint-490\n",
      "Configuration saved in test-nli/checkpoint-490/config.json\n",
      "Model weights saved in test-nli/checkpoint-490/pytorch_model.bin\n",
      "tokenizer config file saved in test-nli/checkpoint-490/tokenizer_config.json\n",
      "Special tokens file saved in test-nli/checkpoint-490/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test-nli/checkpoint-392 (score: 0.3973333333333333).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=0.9852519132653061, metrics={'train_runtime': 288.5789, 'train_samples_per_second': 433.122, 'train_steps_per_second': 1.698, 'total_flos': 2619227819706804.0, 'train_loss': 0.9852519132653061, 'epoch': 5.0})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: source, hypothesis, premise, guid. If source, hypothesis, premise, guid are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3000\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1056615114212036,\n",
       " 'eval_accuracy': 0.37133333333333335,\n",
       " 'eval_runtime': 2.453,\n",
       " 'eval_samples_per_second': 1222.99,\n",
       " 'eval_steps_per_second': 4.892,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMDSPGmMhUYmks1I9B5d2fo",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09db8fe0b55443fdab2ac54e84bb7ff5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_861ab3f25cb4479f9ace3978dc315ecf",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52eabebd19834610890b10347acaf05a",
      "value": 3
     }
    },
    "0a8902cb735d4f658fd387204149ace6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0faf64a0c2af4340ac3b0eed24732d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0614b4ade314c5c8073193bb1d3408f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_38b21b8459234a42b8fb69752644d48a",
      "value": "100%"
     }
    },
    "135dbaaa41a946ca899dc8164bca3e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ad3705618644447bfcfdb9b65271883",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b71e32972c104b53a669ec7591e557ff",
      "value": "100%"
     }
    },
    "155517c19bc24d599b068af7e28ad8cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5da5a29aaa4700bcdbdfc768b33aaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3838ac5a07244d7da893c8ba71b21fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38b21b8459234a42b8fb69752644d48a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b32dbed334941b881ae0e563d7c40ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a8902cb735d4f658fd387204149ace6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e25584843ddd4a4484ec94e7e6c0f6a0",
      "value": 0
     }
    },
    "3ddd98a8524042adba2bbaab1dbf60af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5293a6fc609849eda02622c6fa5b2167": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52eabebd19834610890b10347acaf05a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ad3705618644447bfcfdb9b65271883": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ffb8a1db11a43cb8602ec7af8c55f77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6abc6629a8b0412c9b09ad02c3376127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_155517c19bc24d599b068af7e28ad8cf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3838ac5a07244d7da893c8ba71b21fd9",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "7874b0b368c24ef7b15fac3a4ed83582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9403580e4524754980170c5f1130bd9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1e5da5a29aaa4700bcdbdfc768b33aaf",
      "value": " 1/1 [00:00&lt;00:00,  8.90ba/s]"
     }
    },
    "861ab3f25cb4479f9ace3978dc315ecf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8722d84268664df5a8012a83afd575f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a1e9c4517dc463ba78b91b16431008a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c2682025ce14a88b39dbfc826e33954": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e2728489569432394255a3bb3a80247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af6bdd67d22a42f0be80845511720ae0",
       "IPY_MODEL_3b32dbed334941b881ae0e563d7c40ce",
       "IPY_MODEL_6abc6629a8b0412c9b09ad02c3376127"
      ],
      "layout": "IPY_MODEL_8722d84268664df5a8012a83afd575f3"
     }
    },
    "a255def76d9b4c9db5d9cc7385fc9e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a864568c3b89405cb3ca8e36180f9e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af6bdd67d22a42f0be80845511720ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ddd98a8524042adba2bbaab1dbf60af",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a1e9c4517dc463ba78b91b16431008a",
      "value": ""
     }
    },
    "b0614b4ade314c5c8073193bb1d3408f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b591e297adff46fa8df014fe9192caa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e39bf65dc61a4836805a0a8bd23503a3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a864568c3b89405cb3ca8e36180f9e61",
      "value": " 3/3 [00:00&lt;00:00, 66.64it/s]"
     }
    },
    "b71e32972c104b53a669ec7591e557ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9403580e4524754980170c5f1130bd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cde2d6e48a7748ca840c745e52fa06c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ffb8a1db11a43cb8602ec7af8c55f77",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5293a6fc609849eda02622c6fa5b2167",
      "value": 1
     }
    },
    "e25584843ddd4a4484ec94e7e6c0f6a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e39bf65dc61a4836805a0a8bd23503a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9acdb1a1d2643819339b8f0cf3cecd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_135dbaaa41a946ca899dc8164bca3e44",
       "IPY_MODEL_09db8fe0b55443fdab2ac54e84bb7ff5",
       "IPY_MODEL_b591e297adff46fa8df014fe9192caa3"
      ],
      "layout": "IPY_MODEL_8c2682025ce14a88b39dbfc826e33954"
     }
    },
    "ea941579121247548fdf7774079f2f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0faf64a0c2af4340ac3b0eed24732d5a",
       "IPY_MODEL_cde2d6e48a7748ca840c745e52fa06c2",
       "IPY_MODEL_7874b0b368c24ef7b15fac3a4ed83582"
      ],
      "layout": "IPY_MODEL_a255def76d9b4c9db5d9cc7385fc9e6d"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
